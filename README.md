# Taller: Entrenamiento e inferencia de ML usando Airflow y MLFlow

sudo chown -R 50000:0 ./logs  # Asegura que el directorio tiene los permisos correctos
sudo chmod -R 755 ./logs      # Permite que el contenedor pueda leer y escribir en el directorio

docker network create mynetwork

docker-compose up



## üìå Descripci√≥n

**Este repositorio contiene un entorno para el procesamiento de datos y entrenamiento de modelos basado en `Apache Airflow`, `Docker` y `Python`. Su dise√±o modular permite la automatizaci√≥n de flujos de trabajo con soporte para `PostgreSQL`, `MySQL` y `Redis`, mejorando la gesti√≥n y orquestaci√≥n de tareas en entornos distribuidos.

## üìÇ Estructura del Proyecto

La estructura del proyecto est√° organizada para garantizar una correcta separaci√≥n de responsabilidades y modularidad. Los flujos de trabajo se encuentran en la carpeta `dags/`, donde cada script maneja tareas espec√≠ficas como la carga, eliminaci√≥n y entrenamiento de datos. La carpeta `datos/` contiene los archivos de entrada requeridos para el procesamiento, mientras que `logs/` almacena los registros de ejecuci√≥n para facilitar el monitoreo. Los archivos de configuraci√≥n, como `docker-compose.yml` y `Dockerfile`, permiten la implementaci√≥n del entorno en contenedores, asegurando escalabilidad y reproducibilidad.

```
TALLER_3/
‚îÇ‚îÄ‚îÄ dags/                      # Definici√≥n de flujos de trabajo
‚îÇ   ‚îú‚îÄ‚îÄ carga_datos.py         # Carga de datos
‚îÇ   ‚îú‚îÄ‚îÄ elimina_datos.py       # Eliminaci√≥n de datos
‚îÇ   ‚îú‚îÄ‚îÄ train.py               # Entrenamiento del modelo
‚îÇ‚îÄ‚îÄ datos/                     # Almacenamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ penguins_lter.csv      # Conjunto de datos en formato CSV
‚îÇ‚îÄ‚îÄ logs/                      # Registro de ejecuci√≥n
‚îÇ‚îÄ‚îÄ plugins/                   # Extensiones para Airflow
‚îÇ‚îÄ‚îÄ docker-compose.yml         # Orquestaci√≥n de servicios
‚îÇ‚îÄ‚îÄ Dockerfile                 # Construcci√≥n de la imagen Docker
‚îÇ‚îÄ‚îÄ requirements.txt           # Dependencias del proyecto
```

## üõ† Instancia MySQL
Para crear la instancia de la base de datos mysql, fue necesario incluir el servicio mysql dentro del docker-compose y el volume mysql_data como se encuentra a continuaci√≥n:

```
mysql:
    # Nombre del servicio
    image: mysql:latest  # Imagen Docker para el contenedor MySQL
    ports:
      - "3306:3306"  # Mapeo de puertos del contenedor al host
    environment:
      MYSQL_ROOT_PASSWORD: airflow  # Contrase√±a de root para MySQL
      MYSQL_DATABASE: penguin_data  # Nombre de la base de datos MySQL
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]  # Comando de verificaci√≥n de salud
      interval: 10s  # Frecuencia de la verificaci√≥n de salud
      timeout: 5s  # Tiempo m√°ximo de espera para la verificaci√≥n de salud
      retries: 3  # N√∫mero de intentos de verificaci√≥n de salud
      start_period: 10s  # Tiempo antes de iniciar las verificaciones de salud
    restart: always  # Pol√≠tica de reinicio del contenedor
```

## ‚öôÔ∏è Requisitos

Para ejecutar este repositorio correctamente, es necesario contar con herramientas y configuraciones espec√≠ficas. `Docker` y `Docker Compose` permiten la ejecuci√≥n de los servicios en contenedores, asegurando un entorno reproducible y estable. `Python 3.x` es el lenguaje base para los scripts de procesamiento de datos. Adem√°s, las librer√≠as listadas en `requirements.txt`, como `pandas`, `scikit-learn` e `imbalanced-learn`, proporcionan las funcionalidades necesarias para el an√°lisis de datos y entrenamiento de modelos. Finalmente, `Apache Airflow` gestiona la ejecuci√≥n de tareas automatizadas mediante flujos de trabajo definidos en DAGs.

## üöÄ Instalaci√≥n y Configuraci√≥n

La instalaci√≥n y configuraci√≥n del proyecto se realiza en pocos pasos, asegurando una r√°pida implementaci√≥n del entorno. Primero, se clona el repositorio para obtener el c√≥digo fuente y se accede al directorio del proyecto. Luego, se instalan las dependencias listadas en `requirements.txt`, garantizando que todas las herramientas necesarias est√©n disponibles. Posteriormente, se inician los servicios con `docker-compose`, lo que levanta los contenedores de Airflow, PostgreSQL, MySQL y Redis de manera automatizada. Finalmente, la interfaz web de Airflow puede ser accedida a trav√©s del navegador para gestionar y ejecutar los flujos de trabajo definidos.

1. Clonar el repositorio
```
git clone https://github.com/JohnSanchez27/MLOps_Taller3.git
cd MLOps_Taller3

```

2. Construir el contenedor
```
docker-compose up --build
```

3. Para detener los contenedores sin eliminarlos
```
docker-compose stop
```
4. Acceder a la interfaz de Airflow 
```
 https://localhost:8080 
```

## üèóÔ∏è Arquitectura y Configuraci√≥n de Servicios

La arquitectura del proyecto est√° dise√±ada para garantizar la ejecuci√≥n eficiente y escalable de flujos de trabajo en entornos distribuidos. Airflow gestiona la planificaci√≥n y ejecuci√≥n de tareas mediante `CeleryExecutor`, que permite distribuir la carga entre m√∫ltiples workers. Las bases de datos `PostgreSQL` y `MySQL` almacenan la metadata de Airflow y los datos procesados respectivamente. Redis act√∫a como un `broker` de mensajes, facilitando la comunicaci√≥n entre los diferentes componentes del sistema. El uso de vol√∫menes persistentes asegura la integridad de los datos, evitando p√©rdidas tras reinicios del sistema.

## üî• Retos del Uso de Airflow
El uso de Airflow en entornos productivos conlleva varios desaf√≠os t√©cnicos que deben ser considerados para su correcta implementaci√≥n. La configuraci√≥n inicial requiere definir correctamente las variables de entorno y la conexi√≥n entre servicios. La gesti√≥n de dependencias debe ser precisa para evitar incompatibilidades con la versi√≥n de Airflow utilizada. El monitoreo y depuraci√≥n de errores es esencial debido a la generaci√≥n de m√∫ltiples registros de ejecuci√≥n. Para manejar grandes vol√∫menes de datos, es necesario optimizar la configuraci√≥n de `CeleryExecutor` y los recursos asignados a `Redis`, `PostgreSQL` y `MySQL`. Adem√°s, la estructuraci√≥n adecuada de los DAGs permite optimizar la ejecuci√≥n y reducir tiempos de procesamiento.

## üìä Uso
El proyecto se gestiona a trav√©s de la interfaz web de Airflow, donde se pueden visualizar, programar y ejecutar flujos de trabajo. Los DAGs ubicados en `dags/` pueden ser modificados para adaptarse a nuevos requerimientos o incorporar nuevas funcionalidades. Los registros de ejecuci√≥n almacenados en `logs/` proporcionan informaci√≥n detallada sobre el estado de cada tarea, lo que facilita la depuraci√≥n y optimizaci√≥n del sistema.
